{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzyLknsVtaWvnLjzlHV3m5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caleb-vicente/RL_tutorials/blob/dev/Traveling_Salesman_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We are following the tutorial of page: https://ekimetrics.github.io/blog/2021/11/03/tsp/\n",
        "*   How to create a new gym environment: https://towardsdatascience.com/beginners-guide-to-custom-environments-in-openai-s-gym-989371673952\n",
        "*   Whole solution to the problem can be found here: https://github.com/TheoLvs/reinforcement-learning/blob/master/5.%20Delivery%20Optimization/Optimizing%20delivery%20with%20Reinforcement%20Learning.ipynb"
      ],
      "metadata": {
        "id": "ua7oBrg0F1id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium==0.26.1\n",
        "!pip install \"ray[rllib]\" torch\n",
        "!pip install moviepy==1.0.3\n",
        "!pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdC1JiCVsUW3",
        "outputId": "7ef95e44-ed62-450e-9365-dc9a214971a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gymnasium==0.26.1\n",
            "  Using cached gymnasium-0.26.1-py3-none-any.whl (830 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium==0.26.1) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium==0.26.1) (1.22.4)\n",
            "Requirement already satisfied: gymnasium-notices>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from gymnasium==0.26.1) (0.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium==0.26.1) (6.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gymnasium==0.26.1) (3.15.0)\n",
            "Installing collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: Gymnasium 0.26.3\n",
            "    Uninstalling Gymnasium-0.26.3:\n",
            "      Successfully uninstalled Gymnasium-0.26.3\n",
            "Successfully installed gymnasium-0.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[rllib] in /usr/local/lib/python3.9/dist-packages (2.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (8.1.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (4.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (3.10.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (22.2.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (1.22.4)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (1.3.3)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (1.51.3)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (20.21.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (1.0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (1.10.1)\n",
            "Collecting gymnasium==0.26.3\n",
            "  Using cached Gymnasium-0.26.3-py3-none-any.whl (836 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (0.7.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (0.8.10)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (0.1.8)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (1.4.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (0.19.3)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (4.3.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from ray[rllib]) (13.3.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium==0.26.3->ray[rllib]) (6.1.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gymnasium==0.26.3->ray[rllib]) (1.6.0)\n",
            "Requirement already satisfied: gymnasium-notices>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from gymnasium==0.26.3->ray[rllib]) (0.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX>=1.9->ray[rllib]) (23.0)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray[rllib]) (3.1.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray[rllib]) (0.3.6)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->ray[rllib]) (0.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->ray[rllib]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->ray[rllib]) (2022.7.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ray[rllib]) (1.26.15)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->ray[rllib]) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->ray[rllib]) (2.14.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]) (1.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]) (8.4.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]) (2023.3.21)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->ray[rllib]) (3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gymnasium==0.26.3->ray[rllib]) (3.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->ray[rllib]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->ray[rllib]) (1.16.0)\n",
            "Installing collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 0.26.1\n",
            "    Uninstalling gymnasium-0.26.1:\n",
            "      Successfully uninstalled gymnasium-0.26.1\n",
            "Successfully installed gymnasium-0.26.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.9/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from moviepy==1.0.3) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.9/dist-packages (from moviepy==1.0.3) (0.1.10)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.9/dist-packages (from moviepy==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from moviepy==1.0.3) (0.4.8)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from moviepy==1.0.3) (1.22.4)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.9/dist-packages (from moviepy==1.0.3) (4.65.0)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.9/dist-packages (from moviepy==1.0.3) (2.25.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.9/dist-packages (from imageio<3.0,>=2.5->moviepy==1.0.3) (8.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.9/dist-packages (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Simple Environment"
      ],
      "metadata": {
        "id": "zAM90J-JFYRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0S7G3v1FFS-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "472bddd3-ae4d-42a4-bd89-17b280118253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-0fe864543ac7>:17: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use(\"seaborn-dark\")\n"
          ]
        }
      ],
      "source": [
        "# ===============================================================================================================================================\n",
        "# This enviroment has been obtained from: https://github.com/TheoLvs/reinforcement-learning/blob/master/5.%20Delivery%20Optimization/delivery.py\n",
        "# ===============================================================================================================================================\n",
        "\n",
        "# Base Data Science snippet\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm_notebook\n",
        "from scipy.spatial.distance import cdist\n",
        "import imageio\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.collections import PatchCollection\n",
        "\n",
        "plt.style.use(\"seaborn-dark\")\n",
        "\n",
        "class DeliveryEnvironment(object):\n",
        "    def __init__(self,n_stops = 10,max_box = 10,method = \"distance\",**kwargs):\n",
        "\n",
        "        print(f\"Initialized Delivery Environment with {n_stops} random stops\")\n",
        "        print(f\"Target metric for optimization is {method}\")\n",
        "\n",
        "        # Initialization\n",
        "        self.n_stops = n_stops\n",
        "        self.action_space = self.n_stops\n",
        "        self.observation_space = self.n_stops\n",
        "        self.max_box = max_box\n",
        "        self.stops = []\n",
        "        self.method = method\n",
        "\n",
        "        # Generate stops\n",
        "        self._generate_constraints(**kwargs)\n",
        "        self._generate_stops()\n",
        "        self._generate_q_values()\n",
        "        self.render()\n",
        "\n",
        "        # Initialize first point\n",
        "        self.reset()\n",
        "\n",
        "\n",
        "    def _generate_constraints(self,box_size = 0.2,traffic_intensity = 5):\n",
        "\n",
        "        if self.method == \"traffic_box\":\n",
        "\n",
        "            x_left = np.random.rand() * (self.max_box) * (1-box_size)\n",
        "            y_bottom = np.random.rand() * (self.max_box) * (1-box_size)\n",
        "\n",
        "            x_right = x_left + np.random.rand() * box_size * self.max_box\n",
        "            y_top = y_bottom + np.random.rand() * box_size * self.max_box\n",
        "\n",
        "            self.box = (x_left,x_right,y_bottom,y_top)\n",
        "            self.traffic_intensity = traffic_intensity \n",
        "\n",
        "\n",
        "\n",
        "    def _generate_stops(self):\n",
        "\n",
        "        if self.method == \"traffic_box\":\n",
        "\n",
        "            points = []\n",
        "            while len(points) < self.n_stops:\n",
        "                x,y = np.random.rand(2)*self.max_box\n",
        "                if not self._is_in_box(x,y,self.box):\n",
        "                    points.append((x,y))\n",
        "\n",
        "            xy = np.array(points)\n",
        "\n",
        "        else:\n",
        "            # Generate geographical coordinates\n",
        "            xy = np.random.rand(self.n_stops,2)*self.max_box\n",
        "\n",
        "        self.x = xy[:,0]\n",
        "        self.y = xy[:,1]\n",
        "\n",
        "\n",
        "    def _generate_q_values(self,box_size = 0.2):\n",
        "\n",
        "        # Generate actual Q Values corresponding to time elapsed between two points\n",
        "        if self.method in [\"distance\",\"traffic_box\"]:\n",
        "            xy = np.column_stack([self.x,self.y])\n",
        "            self.q_stops = cdist(xy,xy)\n",
        "        elif self.method==\"time\":\n",
        "            self.q_stops = np.random.rand(self.n_stops,self.n_stops)*self.max_box\n",
        "            np.fill_diagonal(self.q_stops,0)\n",
        "        else:\n",
        "            raise Exception(\"Method not recognized\")\n",
        "    \n",
        "\n",
        "    def render(self,return_img = False):\n",
        "        \n",
        "        fig = plt.figure(figsize=(7,7))\n",
        "        ax = fig.add_subplot(111)\n",
        "        ax.set_title(\"Delivery Stops\")\n",
        "\n",
        "        # Show stops\n",
        "        ax.scatter(self.x,self.y,c = \"red\",s = 50)\n",
        "\n",
        "        # Show START\n",
        "        if len(self.stops)>0:\n",
        "            xy = self._get_xy(initial = True)\n",
        "            xytext = xy[0]+0.1,xy[1]-0.05\n",
        "            ax.annotate(\"START\",xy=xy,xytext=xytext,weight = \"bold\")\n",
        "\n",
        "        # Show itinerary\n",
        "        if len(self.stops) > 1:\n",
        "            ax.plot(self.x[self.stops],self.y[self.stops],c = \"blue\",linewidth=1,linestyle=\"--\")\n",
        "            \n",
        "            # Annotate END\n",
        "            xy = self._get_xy(initial = False)\n",
        "            xytext = xy[0]+0.1,xy[1]-0.05\n",
        "            ax.annotate(\"END\",xy=xy,xytext=xytext,weight = \"bold\")\n",
        "\n",
        "\n",
        "        if hasattr(self,\"box\"):\n",
        "            left,bottom = self.box[0],self.box[2]\n",
        "            width = self.box[1] - self.box[0]\n",
        "            height = self.box[3] - self.box[2]\n",
        "            rect = Rectangle((left,bottom), width, height)\n",
        "            collection = PatchCollection([rect],facecolor = \"red\",alpha = 0.2)\n",
        "            ax.add_collection(collection)\n",
        "\n",
        "\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        \n",
        "        if return_img:\n",
        "            # From https://ndres.me/post/matplotlib-animated-gifs-easily/\n",
        "            fig.canvas.draw_idle()\n",
        "            image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
        "            image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "            plt.close()\n",
        "            return image\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "\n",
        "        # Stops placeholder\n",
        "        self.stops = []\n",
        "\n",
        "        # Random first stop\n",
        "        first_stop = np.random.randint(self.n_stops)\n",
        "        self.stops.append(first_stop)\n",
        "\n",
        "        return first_stop\n",
        "\n",
        "\n",
        "    def step(self,destination):\n",
        "\n",
        "        # Get current state\n",
        "        state = self._get_state()\n",
        "        new_state = destination\n",
        "\n",
        "        # Get reward for such a move\n",
        "        reward = self._get_reward(state,new_state)\n",
        "\n",
        "        # Append new_state to stops\n",
        "        self.stops.append(destination)\n",
        "        done = len(self.stops) == self.n_stops\n",
        "\n",
        "        return new_state,reward,done\n",
        "    \n",
        "\n",
        "    def _get_state(self):\n",
        "        return self.stops[-1]\n",
        "\n",
        "\n",
        "    def _get_xy(self,initial = False):\n",
        "        state = self.stops[0] if initial else self._get_state()\n",
        "        x = self.x[state]\n",
        "        y = self.y[state]\n",
        "        return x,y\n",
        "\n",
        "\n",
        "    def _get_reward(self,state,new_state):\n",
        "        base_reward = self.q_stops[state,new_state]\n",
        "\n",
        "        if self.method == \"distance\":\n",
        "            return base_reward\n",
        "        elif self.method == \"time\":\n",
        "            return base_reward + np.random.randn()\n",
        "        elif self.method == \"traffic_box\":\n",
        "\n",
        "            # Additional reward correspond to slowing down in traffic\n",
        "            xs,ys = self.x[state],self.y[state]\n",
        "            xe,ye = self.x[new_state],self.y[new_state]\n",
        "            intersections = self._calculate_box_intersection(xs,xe,ys,ye,self.box)\n",
        "            if len(intersections) > 0:\n",
        "                i1,i2 = intersections\n",
        "                distance_traffic = np.sqrt((i2[1]-i1[1])**2 + (i2[0]-i1[0])**2)\n",
        "                additional_reward = distance_traffic * self.traffic_intensity * np.random.rand()\n",
        "            else:\n",
        "                additional_reward = np.random.rand()\n",
        "\n",
        "            return base_reward + additional_reward\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _calculate_point(x1,x2,y1,y2,x = None,y = None):\n",
        "\n",
        "        if y1 == y2:\n",
        "            return y1\n",
        "        elif x1 == x2:\n",
        "            return x1\n",
        "        else:\n",
        "            a = (y2-y1)/(x2-x1)\n",
        "            b = y2 - a * x2\n",
        "\n",
        "            if x is None:\n",
        "                x = (y-b)/a\n",
        "                return x\n",
        "            elif y is None:\n",
        "                y = a*x+b\n",
        "                return y\n",
        "            else:\n",
        "                raise Exception(\"Provide x or y\")\n",
        "\n",
        "\n",
        "    def _is_in_box(self,x,y,box):\n",
        "        # Get box coordinates\n",
        "        x_left,x_right,y_bottom,y_top = box\n",
        "        return x >= x_left and x <= x_right and y >= y_bottom and y <= y_top\n",
        "\n",
        "\n",
        "    def _calculate_box_intersection(self,x1,x2,y1,y2,box):\n",
        "\n",
        "        # Get box coordinates\n",
        "        x_left,x_right,y_bottom,y_top = box\n",
        "\n",
        "        # Intersections\n",
        "        intersections = []\n",
        "\n",
        "        # Top intersection\n",
        "        i_top = self._calculate_point(x1,x2,y1,y2,y=y_top)\n",
        "        if i_top > x_left and i_top < x_right:\n",
        "            intersections.append((i_top,y_top))\n",
        "\n",
        "        # Bottom intersection\n",
        "        i_bottom = self._calculate_point(x1,x2,y1,y2,y=y_bottom)\n",
        "        if i_bottom > x_left and i_bottom < x_right:\n",
        "            intersections.append((i_bottom,y_bottom))\n",
        "\n",
        "        # Left intersection\n",
        "        i_left = self._calculate_point(x1,x2,y1,y2,x=x_left)\n",
        "        if i_left > y_bottom and i_left < y_top:\n",
        "            intersections.append((x_left,i_left))\n",
        "\n",
        "        # Right intersection\n",
        "        i_right = self._calculate_point(x1,x2,y1,y2,x=x_right)\n",
        "        if i_right > y_bottom and i_right < y_top:\n",
        "            intersections.append((x_right,i_right))\n",
        "\n",
        "        return intersections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create same environmet with gym"
      ],
      "metadata": {
        "id": "kFSmkoggns74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium\n",
        "from gymnasium import spaces\n",
        "\n",
        "class DeliveryEnv(gymnasium.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, n_stops=10, max_box=10, method=\"distance\", **kwargs):\n",
        "        self.n_stops = n_stops\n",
        "        self.max_box = max_box\n",
        "        self.method = method\n",
        "        self.kwargs = kwargs\n",
        "        self.delivery_env = DeliveryEnvironment(n_stops=n_stops, max_box=max_box, method=method, **kwargs)\n",
        "        self.action_space = spaces.Discrete(n_stops)\n",
        "        self.observation_space = spaces.Discrete(n_stops)\n",
        "        self.state = None\n",
        "\n",
        "    def step(self, action):\n",
        "        state, reward, done = self.delivery_env.step(action)\n",
        "        self.state = state\n",
        "        if done:\n",
        "            reward = -100\n",
        "        return state, reward, done\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.delivery_env.reset()\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        return self.delivery_env.render(return_img=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "xVJYecnEriq2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = DeliveryEnv(n_stops=100, max_box=10, method=\"distance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "hykhpQyTrqgI",
        "outputId": "91d8d93d-a1fd-401b-d3a4-a0d1447f762b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Delivery Environment with 100 random stops\n",
            "Target metric for optimization is distance\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOdw4D1rH1Ew",
        "outputId": "a0fe8a32-5966-4292-a9b1-af6a3755462f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(100)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.step(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slmOzsszH3j6",
        "outputId": "6454309a-82c6-45da-fb52-8b0ddb79de47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 9.214996684794462, False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training algorithm RL"
      ],
      "metadata": {
        "id": "WQFNyNNoFe4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "\n",
        "ray.init(num_cpus=3, ignore_reinit_error=True, log_to_driver=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "aTX4RW9Ct18X",
        "outputId": "c383da1d-ebf0-4798-80b7-01dea6531497"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-26 13:36:46,894\tINFO worker.py:1553 -- Started a local Ray instance.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='', python_version='3.9.16', ray_version='2.3.1', ray_commit='5f14cee8dfc6d61ec4fd3bc2c440f9944e92b33a', address_info={'node_ip_address': '172.28.0.12', 'raylet_ip_address': '172.28.0.12', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-03-26_13-36-42_888884_40267/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-03-26_13-36-42_888884_40267/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-03-26_13-36-42_888884_40267', 'metrics_export_port': 63239, 'gcs_address': '172.28.0.12:62446', 'address': '172.28.0.12:62446', 'dashboard_agent_listen_port': 52365, 'node_id': '18b85da8738fb4048280e28c8780f14a52cf2571fccbc9b85e5d9277'})"
            ],
            "text/html": [
              "<div>\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
              "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
              "            <g id=\"layer-1\">\n",
              "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
              "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
              "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
              "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
              "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
              "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
              "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
              "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
              "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
              "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
              "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
              "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
              "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
              "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
              "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
              "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
              "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
              "            </g>\n",
              "        </svg>\n",
              "        <table>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "                <td style=\"text-align: left\"><b>3.9.16</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "                <td style=\"text-align: left\"><b> 2.3.1</b></td>\n",
              "            </tr>\n",
              "            \n",
              "        </table>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.rllib.algorithms.dqn.dqn import DQNConfig\n",
        "from ray.tune.registry import register_env\n",
        "from ray import tune\n",
        "from ray import air\n",
        "from ray import tune\n",
        "import os\n",
        "\n",
        "# Register the custom environment\n",
        "def env_creator(env_config):\n",
        "    return DeliveryEnv(n_stops=env_config['n_stops'])\n",
        "\n",
        "register_env(\"DeliveryEnv-v0\", env_creator)\n",
        "\n",
        "config = DQNConfig()\n",
        "config.training(lr=tune.grid_search([0.001, 0.0001]))\n",
        "\n",
        "# Set the config object's env.\n",
        "config = config.environment(env='DeliveryEnv-v0', env_config={'n_stops': 150})\n",
        "config = config.framework(\"torch\")\n",
        "# Use to_dict() to get the old-style python config dict\n",
        "# when running with tune.\n",
        "tuner = tune.Tuner(  # doctest: +SKIP\n",
        "     \"DQN\",\n",
        "     run_config=air.RunConfig(stop= {\"training_iteration\": 8},\n",
        "                              local_dir=\"./results\"),\n",
        "     param_space=config.to_dict(),\n",
        ")\n",
        "\n",
        "results = tuner.fit()"
      ],
      "metadata": {
        "id": "4lYwoCTgFohk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "841bdec8-99ec-449a-d18d-1c5f240a81fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/flax/core/frozen_dict.py:169: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2023-03-26 13:37:25</td></tr>\n",
              "<tr><td>Running for: </td><td>00:00:27.41        </td></tr>\n",
              "<tr><td>Memory:      </td><td>2.2/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using FIFO scheduling algorithm.<br>Resources requested: 0/3 CPUs, 0/0 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "<div class=\"messages\">\n",
              "  <h3>Messages</h3>\n",
              "  \n",
              "  \n",
              "  Number of errored trials: 2<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                   </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_DeliveryEnv-v0_47d3c_00000</td><td style=\"text-align: right;\">           1</td><td>/content/results/DQN/DQN_DeliveryEnv-v0_47d3c_00000_0_lr=0.0010_2023-03-26_13-36-59/error.txt</td></tr>\n",
              "<tr><td>DQN_DeliveryEnv-v0_47d3c_00001</td><td style=\"text-align: right;\">           1</td><td>/content/results/DQN/DQN_DeliveryEnv-v0_47d3c_00001_1_lr=0.0001_2023-03-26_13-37-16/error.txt</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".messages {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  padding-left: 1em;\n",
              "  overflow-y: auto;\n",
              "}\n",
              ".messages h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n",
              "\n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name                    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_DeliveryEnv-v0_47d3c_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.001 </td></tr>\n",
              "<tr><td>DQN_DeliveryEnv-v0_47d3c_00001</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-26 13:37:25,589\tERROR trial_runner.py:1062 -- Trial DQN_DeliveryEnv-v0_47d3c_00000: Error processing event.\n",
            "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/tune/execution/ray_trial_executor.py\", line 1276, in get_next_executor_event\n",
            "    future_result = ray.get(ready_future)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/_private/worker.py\", line 2382, in get\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 1166, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1072, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 805, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 972, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 621, in ray._raylet.store_task_errors\n",
            "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "TypeError: reset() got an unexpected keyword argument 'seed'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 82, in check_env\n",
            "    check_gym_environments(env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 195, in check_gym_environments\n",
            "    raise ValueError(\n",
            "ValueError: Your environment (<DeliveryEnv instance>) does not abide to the new gymnasium-style API!\n",
            "From Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\n",
            "In particular, the `reset()` method seems to be faulty.\n",
            "Learn more about the most important changes here:\n",
            "https://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n",
            "\n",
            "In order to fix this problem, do the following:\n",
            "\n",
            "1) Run `pip install gymnasium` on your command line.\n",
            "2) Change all your import statements in your code from\n",
            "   `import gym` -> `import gymnasium as gym` OR\n",
            "   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n",
            "\n",
            "For your custom (single agent) gym.Env classes:\n",
            "3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n",
            "     EnvCompatibility` wrapper class.\n",
            "3.2) Alternatively to 3.1:\n",
            " - Change your `reset()` method to have the call signature 'def reset(self, *,\n",
            "   seed=None, options=None)'\n",
            " - Return an additional info dict (empty dict should be fine) from your `reset()`\n",
            "   method.\n",
            " - Return an additional `truncated` flag from your `step()` method (between `done` and\n",
            "   `info`). This flag should indicate, whether the episode was terminated prematurely\n",
            "   due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "For your custom RLlib `MultiAgentEnv` classes:\n",
            "4.1) Either wrap your old MultiAgentEnv via the provided\n",
            "     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n",
            "     MultiAgentEnvCompatibility` wrapper class.\n",
            "4.2) Alternatively to 4.1:\n",
            " - Change your `reset()` method to have the call signature\n",
            "   'def reset(self, *, seed=None, options=None)'\n",
            " - Return an additional per-agent info dict (empty dict should be fine) from your\n",
            "   `reset()` method.\n",
            " - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n",
            "   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n",
            "   setting).\n",
            " - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n",
            "   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n",
            "   per-agent dict).\n",
            "   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n",
            "   flag should indicate, whether the episode (for some agent or all agents) was\n",
            "   terminated prematurely due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/algorithms/algorithm.py\", line 445, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/algorithms/algorithm.py\", line 571, in setup\n",
            "    self.workers = WorkerSet(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 170, in __init__\n",
            "    self._setup(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 260, in _setup\n",
            "    self._local_worker = self._make_worker(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 946, in _make_worker\n",
            "    worker = cls(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 614, in __init__\n",
            "    check_env(self.env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 93, in check_env\n",
            "    raise ValueError(\n",
            "ValueError: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 192, in check_gym_environments\n",
            "    obs_and_infos = env.reset(seed=None, options={})\n",
            "TypeError: reset() got an unexpected keyword argument 'seed'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 82, in check_env\n",
            "    check_gym_environments(env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 195, in check_gym_environments\n",
            "    raise ValueError(\n",
            "ValueError: Your environment (<DeliveryEnv instance>) does not abide to the new gymnasium-style API!\n",
            "From Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\n",
            "In particular, the `reset()` method seems to be faulty.\n",
            "Learn more about the most important changes here:\n",
            "https://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n",
            "\n",
            "In order to fix this problem, do the following:\n",
            "\n",
            "1) Run `pip install gymnasium` on your command line.\n",
            "2) Change all your import statements in your code from\n",
            "   `import gym` -> `import gymnasium as gym` OR\n",
            "   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n",
            "\n",
            "For your custom (single agent) gym.Env classes:\n",
            "3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n",
            "     EnvCompatibility` wrapper class.\n",
            "3.2) Alternatively to 3.1:\n",
            " - Change your `reset()` method to have the call signature 'def reset(self, *,\n",
            "   seed=None, options=None)'\n",
            " - Return an additional info dict (empty dict should be fine) from your `reset()`\n",
            "   method.\n",
            " - Return an additional `truncated` flag from your `step()` method (between `done` and\n",
            "   `info`). This flag should indicate, whether the episode was terminated prematurely\n",
            "   due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "For your custom RLlib `MultiAgentEnv` classes:\n",
            "4.1) Either wrap your old MultiAgentEnv via the provided\n",
            "     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n",
            "     MultiAgentEnvCompatibility` wrapper class.\n",
            "4.2) Alternatively to 4.1:\n",
            " - Change your `reset()` method to have the call signature\n",
            "   'def reset(self, *, seed=None, options=None)'\n",
            " - Return an additional per-agent info dict (empty dict should be fine) from your\n",
            "   `reset()` method.\n",
            " - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n",
            "   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n",
            "   setting).\n",
            " - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n",
            "   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n",
            "   per-agent dict).\n",
            "   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n",
            "   flag should indicate, whether the episode (for some agent or all agents) was\n",
            "   terminated prematurely due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "\n",
            "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior via calling `config.environment(disable_env_checking=True)`. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([your env]).\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name                    </th><th>trial_id   </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>DQN_DeliveryEnv-v0_47d3c_00000</td><td>47d3c_00000</td></tr>\n",
              "<tr><td>DQN_DeliveryEnv-v0_47d3c_00001</td><td>47d3c_00001</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-26 13:37:25,608\tERROR ray_trial_executor.py:930 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/tune/execution/ray_trial_executor.py\", line 921, in _resolve_stop_event\n",
            "    ray.get(future, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/_private/worker.py\", line 2382, in get\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 1166, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1072, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 805, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 972, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 621, in ray._raylet.store_task_errors\n",
            "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "TypeError: reset() got an unexpected keyword argument 'seed'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 82, in check_env\n",
            "    check_gym_environments(env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 195, in check_gym_environments\n",
            "    raise ValueError(\n",
            "ValueError: Your environment (<DeliveryEnv instance>) does not abide to the new gymnasium-style API!\n",
            "From Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\n",
            "In particular, the `reset()` method seems to be faulty.\n",
            "Learn more about the most important changes here:\n",
            "https://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n",
            "\n",
            "In order to fix this problem, do the following:\n",
            "\n",
            "1) Run `pip install gymnasium` on your command line.\n",
            "2) Change all your import statements in your code from\n",
            "   `import gym` -> `import gymnasium as gym` OR\n",
            "   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n",
            "\n",
            "For your custom (single agent) gym.Env classes:\n",
            "3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n",
            "     EnvCompatibility` wrapper class.\n",
            "3.2) Alternatively to 3.1:\n",
            " - Change your `reset()` method to have the call signature 'def reset(self, *,\n",
            "   seed=None, options=None)'\n",
            " - Return an additional info dict (empty dict should be fine) from your `reset()`\n",
            "   method.\n",
            " - Return an additional `truncated` flag from your `step()` method (between `done` and\n",
            "   `info`). This flag should indicate, whether the episode was terminated prematurely\n",
            "   due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "For your custom RLlib `MultiAgentEnv` classes:\n",
            "4.1) Either wrap your old MultiAgentEnv via the provided\n",
            "     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n",
            "     MultiAgentEnvCompatibility` wrapper class.\n",
            "4.2) Alternatively to 4.1:\n",
            " - Change your `reset()` method to have the call signature\n",
            "   'def reset(self, *, seed=None, options=None)'\n",
            " - Return an additional per-agent info dict (empty dict should be fine) from your\n",
            "   `reset()` method.\n",
            " - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n",
            "   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n",
            "   setting).\n",
            " - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n",
            "   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n",
            "   per-agent dict).\n",
            "   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n",
            "   flag should indicate, whether the episode (for some agent or all agents) was\n",
            "   terminated prematurely due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/algorithms/algorithm.py\", line 445, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/algorithms/algorithm.py\", line 571, in setup\n",
            "    self.workers = WorkerSet(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 170, in __init__\n",
            "    self._setup(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 260, in _setup\n",
            "    self._local_worker = self._make_worker(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 946, in _make_worker\n",
            "    worker = cls(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 614, in __init__\n",
            "    check_env(self.env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 93, in check_env\n",
            "    raise ValueError(\n",
            "ValueError: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 192, in check_gym_environments\n",
            "    obs_and_infos = env.reset(seed=None, options={})\n",
            "TypeError: reset() got an unexpected keyword argument 'seed'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40866, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 82, in check_env\n",
            "    check_gym_environments(env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 195, in check_gym_environments\n",
            "    raise ValueError(\n",
            "ValueError: Your environment (<DeliveryEnv instance>) does not abide to the new gymnasium-style API!\n",
            "From Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\n",
            "In particular, the `reset()` method seems to be faulty.\n",
            "Learn more about the most important changes here:\n",
            "https://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n",
            "\n",
            "In order to fix this problem, do the following:\n",
            "\n",
            "1) Run `pip install gymnasium` on your command line.\n",
            "2) Change all your import statements in your code from\n",
            "   `import gym` -> `import gymnasium as gym` OR\n",
            "   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n",
            "\n",
            "For your custom (single agent) gym.Env classes:\n",
            "3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n",
            "     EnvCompatibility` wrapper class.\n",
            "3.2) Alternatively to 3.1:\n",
            " - Change your `reset()` method to have the call signature 'def reset(self, *,\n",
            "   seed=None, options=None)'\n",
            " - Return an additional info dict (empty dict should be fine) from your `reset()`\n",
            "   method.\n",
            " - Return an additional `truncated` flag from your `step()` method (between `done` and\n",
            "   `info`). This flag should indicate, whether the episode was terminated prematurely\n",
            "   due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "For your custom RLlib `MultiAgentEnv` classes:\n",
            "4.1) Either wrap your old MultiAgentEnv via the provided\n",
            "     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n",
            "     MultiAgentEnvCompatibility` wrapper class.\n",
            "4.2) Alternatively to 4.1:\n",
            " - Change your `reset()` method to have the call signature\n",
            "   'def reset(self, *, seed=None, options=None)'\n",
            " - Return an additional per-agent info dict (empty dict should be fine) from your\n",
            "   `reset()` method.\n",
            " - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n",
            "   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n",
            "   setting).\n",
            " - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n",
            "   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n",
            "   per-agent dict).\n",
            "   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n",
            "   flag should indicate, whether the episode (for some agent or all agents) was\n",
            "   terminated prematurely due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "\n",
            "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior via calling `config.environment(disable_env_checking=True)`. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([your env]).\n",
            "\n",
            "2023-03-26 13:37:25,620\tERROR trial_runner.py:1062 -- Trial DQN_DeliveryEnv-v0_47d3c_00001: Error processing event.\n",
            "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/tune/execution/ray_trial_executor.py\", line 1276, in get_next_executor_event\n",
            "    future_result = ray.get(ready_future)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/_private/worker.py\", line 2382, in get\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 1166, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1072, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 805, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 972, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 621, in ray._raylet.store_task_errors\n",
            "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::DQN.__init__()\u001b[39m (pid=40971, ip=172.28.0.12, repr=DQN)\n",
            "TypeError: reset() got an unexpected keyword argument 'seed'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40971, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 82, in check_env\n",
            "    check_gym_environments(env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 195, in check_gym_environments\n",
            "    raise ValueError(\n",
            "ValueError: Your environment (<DeliveryEnv instance>) does not abide to the new gymnasium-style API!\n",
            "From Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\n",
            "In particular, the `reset()` method seems to be faulty.\n",
            "Learn more about the most important changes here:\n",
            "https://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n",
            "\n",
            "In order to fix this problem, do the following:\n",
            "\n",
            "1) Run `pip install gymnasium` on your command line.\n",
            "2) Change all your import statements in your code from\n",
            "   `import gym` -> `import gymnasium as gym` OR\n",
            "   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n",
            "\n",
            "For your custom (single agent) gym.Env classes:\n",
            "3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n",
            "     EnvCompatibility` wrapper class.\n",
            "3.2) Alternatively to 3.1:\n",
            " - Change your `reset()` method to have the call signature 'def reset(self, *,\n",
            "   seed=None, options=None)'\n",
            " - Return an additional info dict (empty dict should be fine) from your `reset()`\n",
            "   method.\n",
            " - Return an additional `truncated` flag from your `step()` method (between `done` and\n",
            "   `info`). This flag should indicate, whether the episode was terminated prematurely\n",
            "   due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "For your custom RLlib `MultiAgentEnv` classes:\n",
            "4.1) Either wrap your old MultiAgentEnv via the provided\n",
            "     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n",
            "     MultiAgentEnvCompatibility` wrapper class.\n",
            "4.2) Alternatively to 4.1:\n",
            " - Change your `reset()` method to have the call signature\n",
            "   'def reset(self, *, seed=None, options=None)'\n",
            " - Return an additional per-agent info dict (empty dict should be fine) from your\n",
            "   `reset()` method.\n",
            " - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n",
            "   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n",
            "   setting).\n",
            " - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n",
            "   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n",
            "   per-agent dict).\n",
            "   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n",
            "   flag should indicate, whether the episode (for some agent or all agents) was\n",
            "   terminated prematurely due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40971, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/algorithms/algorithm.py\", line 445, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/algorithms/algorithm.py\", line 571, in setup\n",
            "    self.workers = WorkerSet(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 170, in __init__\n",
            "    self._setup(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 260, in _setup\n",
            "    self._local_worker = self._make_worker(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/worker_set.py\", line 946, in _make_worker\n",
            "    worker = cls(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/evaluation/rollout_worker.py\", line 614, in __init__\n",
            "    check_env(self.env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 93, in check_env\n",
            "    raise ValueError(\n",
            "ValueError: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 192, in check_gym_environments\n",
            "    obs_and_infos = env.reset(seed=None, options={})\n",
            "TypeError: reset() got an unexpected keyword argument 'seed'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "\u001b[36mray::DQN.__init__()\u001b[39m (pid=40971, ip=172.28.0.12, repr=DQN)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 82, in check_env\n",
            "    check_gym_environments(env)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ray/rllib/utils/pre_checks/env.py\", line 195, in check_gym_environments\n",
            "    raise ValueError(\n",
            "ValueError: Your environment (<DeliveryEnv instance>) does not abide to the new gymnasium-style API!\n",
            "From Ray 2.3 on, RLlib only supports the new (gym>=0.26 or gymnasium) Env APIs.\n",
            "In particular, the `reset()` method seems to be faulty.\n",
            "Learn more about the most important changes here:\n",
            "https://github.com/openai/gym and here: https://github.com/Farama-Foundation/Gymnasium\n",
            "\n",
            "In order to fix this problem, do the following:\n",
            "\n",
            "1) Run `pip install gymnasium` on your command line.\n",
            "2) Change all your import statements in your code from\n",
            "   `import gym` -> `import gymnasium as gym` OR\n",
            "   `from gym.space import Discrete` -> `from gymnasium.spaces import Discrete`\n",
            "\n",
            "For your custom (single agent) gym.Env classes:\n",
            "3.1) Either wrap your old Env class via the provided `from gymnasium.wrappers import\n",
            "     EnvCompatibility` wrapper class.\n",
            "3.2) Alternatively to 3.1:\n",
            " - Change your `reset()` method to have the call signature 'def reset(self, *,\n",
            "   seed=None, options=None)'\n",
            " - Return an additional info dict (empty dict should be fine) from your `reset()`\n",
            "   method.\n",
            " - Return an additional `truncated` flag from your `step()` method (between `done` and\n",
            "   `info`). This flag should indicate, whether the episode was terminated prematurely\n",
            "   due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "For your custom RLlib `MultiAgentEnv` classes:\n",
            "4.1) Either wrap your old MultiAgentEnv via the provided\n",
            "     `from ray.rllib.env.wrappers.multi_agent_env_compatibility import\n",
            "     MultiAgentEnvCompatibility` wrapper class.\n",
            "4.2) Alternatively to 4.1:\n",
            " - Change your `reset()` method to have the call signature\n",
            "   'def reset(self, *, seed=None, options=None)'\n",
            " - Return an additional per-agent info dict (empty dict should be fine) from your\n",
            "   `reset()` method.\n",
            " - Rename `dones` into `terminateds` and only set this to True, if the episode is really\n",
            "   done (as opposed to has been terminated prematurely due to some horizon/time-limit\n",
            "   setting).\n",
            " - Return an additional `truncateds` per-agent dictionary flag from your `step()`\n",
            "   method, including the `__all__` key (100% analogous to your `dones/terminateds`\n",
            "   per-agent dict).\n",
            "   Return this new `truncateds` dict between `dones/terminateds` and `infos`. This\n",
            "   flag should indicate, whether the episode (for some agent or all agents) was\n",
            "   terminated prematurely due to some time constraint or other kind of horizon setting.\n",
            "\n",
            "\n",
            "The above error has been found in your environment! We've added a module for checking your custom environments. It may cause your experiment to fail if your environment is not set up correctly. You can disable this behavior via calling `config.environment(disable_env_checking=True)`. You can run the environment checking module standalone by calling ray.rllib.utils.check_env([your env]).\n",
            "\n",
            "2023-03-26 13:37:25,651\tERROR tune.py:794 -- Trials did not complete: [DQN_DeliveryEnv-v0_47d3c_00000, DQN_DeliveryEnv-v0_47d3c_00001]\n",
            "2023-03-26 13:37:25,653\tINFO tune.py:798 -- Total run time: 27.49 seconds (27.40 seconds for the tuning loop).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Genetic Algorithm"
      ],
      "metadata": {
        "id": "xYw34a_VFo4I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_JC_qSbFuxl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increase Environment"
      ],
      "metadata": {
        "id": "AbMJJFyIFvSl"
      }
    }
  ]
}